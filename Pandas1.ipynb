{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3TywX7TRbu9sF/8mv5hle",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kedarvartak/Machine-Learning/blob/main/Pandas1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Pandas"
      ],
      "metadata": {
        "id": "3tBL2aCJpH57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "D-JpYqIjpPrZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Series in Pandas\n",
        "Series in pandas is basically like a 1D array, so why do we use Series and not just use a list in python, this is because in machine learning we often need common functions like mean, mode, median etc. Series provides us with in built functions for these, which comes in handy"
      ],
      "metadata": {
        "id": "qDs3PmaVpk5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [1, 2, 3, 4, 5]\n",
        "series = pd.Series(data)\n",
        "print(series)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y1Sut9Tp86o",
        "outputId": "580292e4-6f6c-4820-fc20-ec9e69784470"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    1\n",
            "1    2\n",
            "2    3\n",
            "3    4\n",
            "4    5\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Problem with Series\n",
        "To be honest there is no problem with series, in real life we dont get much data which is in 1D format, most data is present in 2D format so series is pretty much useless\n",
        "\n",
        "# Which is why we are here to learn DataFrame\n",
        "Dataframe is series for 2D data but the data is not actually 2 Dimensional, imagine a CSV file which consists of lots and lots of rows and columns, note that not every row or column has SAME TYPE OF DATA , datatype might differ. In technical language, in a Dataframe we have heterogenous datatypes"
      ],
      "metadata": {
        "id": "3YrLmpu8qbZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRUIsJvXqw-Y",
        "outputId": "c40a038e-69a7-442a-cde5-72abf851b526"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0  1  2\n",
            "0  1  2  3\n",
            "1  4  5  6\n",
            "2  7  8  9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cool Facts alert\n",
        "most of the times when it comes to a dataset you hear of .csv files or .xlsx file formatted dataset, but do you know that these formats are not efficient and arent used for large datasets, So what is ?\n",
        "\n",
        "1. PARQUET FILE - Columnar file format , a part of apache ecosystem\n",
        "2. FEATHER FILE - binary columnar format\n",
        "\n",
        "while a csv file would take 1-2GB for a dataset, a parquet file would wrap it up for the same dataset into 100-200MB file"
      ],
      "metadata": {
        "id": "gWfv8wbqsFvR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fym6Xdftsljp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}